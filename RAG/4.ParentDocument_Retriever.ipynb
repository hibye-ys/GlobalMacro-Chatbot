{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from langchain_core.documents import Document\n",
    "from datetime import datetime\n",
    "from DataProcessing.utils import load_yaml\n",
    "from DataProcessing.extract_graphstate import (\n",
    "    extract_documents_for_singlestore,\n",
    ")\n",
    "\n",
    "config = load_yaml(\"../config/embedding.yaml\")\n",
    "category_id = config[\"settings\"][\"category_id\"]\n",
    "filetype = config[\"settings\"][\"filetype\"]\n",
    "edit_path = config[\"settings\"][\"edit_path\"]\n",
    "# path = os.path.join(edit_path, category_id, \"json\")\n",
    "output_path = config[\"settings\"][\"output_path\"]\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_json_files(path):\n",
    "    data_list = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(path, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "                data = json.load(file)\n",
    "                data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "\n",
    "data_list = []\n",
    "for category in config[\"settings\"][\"category_id\"]:\n",
    "    category_path = os.path.join(edit_path, category, \"json\")\n",
    "    data_list.extend(load_json_files(category_path))\n",
    "\n",
    "all_documents = []\n",
    "for data in data_list:\n",
    "    document = extract_documents_for_singlestore(data)\n",
    "    all_documents.extend(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain_upstage.embeddings import UpstageEmbeddings\n",
    "import uuid\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_upstage.embeddings import UpstageEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from datetime import datetime\n",
    "from langchain.storage.encoder_backed import EncoderBackedStore\n",
    "import pickle\n",
    "\n",
    "\n",
    "def key_encoder(key: int | str) -> str:\n",
    "    return str(key)\n",
    "\n",
    "\n",
    "def value_serializer(value: float) -> str:\n",
    "    return pickle.dumps(value)\n",
    "\n",
    "\n",
    "def value_deserializer(serialized_value: str) -> float:\n",
    "    return pickle.loads(serialized_value)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "time = datetime.now().strftime(\"%Y.%m.%d\")\n",
    "proj_name = f\"2024.09.14_for_parentdocument_store\"\n",
    "store = LocalFileStore(\n",
    "    f\"/Users/youngseoklee/Desktop/workplace/MacroAgent-withRAG/cache/{proj_name}/data\"\n",
    ")\n",
    "\n",
    "encoder_store = EncoderBackedStore(\n",
    "    store=store,\n",
    "    key_encoder=key_encoder,\n",
    "    value_serializer=value_serializer,\n",
    "    value_deserializer=value_deserializer,\n",
    ")\n",
    "\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)\n",
    "passage_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")\n",
    "\n",
    "\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings=passage_embeddings,\n",
    "    document_embedding_cache=store,\n",
    "    namespace=passage_embeddings.model,\n",
    ")\n",
    "DB_PATH = f\"/Users/youngseoklee/Desktop/workplace/MacroAgent-withRAG/db/2024.09.14_for_parentdocument_store\"\n",
    "db = Chroma(persist_directory=DB_PATH, embedding_function=cached_embedder)\n",
    "\n",
    "\n",
    "Parent_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=db,\n",
    "    docstore=encoder_store,\n",
    "    child_splitter=child_splitter,\n",
    ")\n",
    "\n",
    "\n",
    "filtered_all_documents = filter_complex_metadata(documents=all_documents)\n",
    "\n",
    "Parent_retriever.add_documents(\n",
    "    documents=filtered_all_documents, ids=None, add_to_docstore=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = Parent_retriever.invoke(\"엔화의 전망에 대해 알려줘\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from DataProcessing.utils import load_yaml\n",
    "\n",
    "\n",
    "path = \"./data/custom_testdataset.xlsx\"\n",
    "# testset = pd.read_csv(path)\n",
    "testset = pd.read_excel(path)\n",
    "\n",
    "questions = testset[\"question\"].to_list()\n",
    "ground_truth = testset[\"ground_truth\"].to_list()\n",
    "\n",
    "data = {\"question\": [], \"answer\": [], \"contexts\": [], \"ground_truth\": ground_truth}\n",
    "\n",
    "prompt_template = load_yaml(\"../prompts/Retriever._prompt.yaml\")[\"prompt\"]\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0.5)\n",
    "rag_chain = (\n",
    "    {\"context\": Parent_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "for query in questions:\n",
    "    data[\"question\"].append(query)\n",
    "    data[\"answer\"].append(rag_chain.invoke(query))\n",
    "    data[\"contexts\"].append(\n",
    "        [doc.page_content for doc in Parent_retriever.invoke(query)]\n",
    "    )\n",
    "\n",
    "path = \"./data/customtestset_sonnet_parentdocument.json\"\n",
    "with open(path, \"w\") as file:\n",
    "    json.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macroagent-withrag-bsFmSw79-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
