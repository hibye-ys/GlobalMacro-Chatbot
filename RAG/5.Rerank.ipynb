{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25_Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init_pinecone_index]\n",
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'financical-data-00': {'vector_count': 2012}},\n",
      " 'total_vector_count': 2012}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote.community.pinecone import init_pinecone_index\n",
    "from langchain_upstage.embeddings import UpstageEmbeddings\n",
    "from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetriever\n",
    "from langchain_teddynote.korean import stopwords\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "pinecone_params = init_pinecone_index(\n",
    "    index_name=\"globalmacro-chatbot\",\n",
    "    namespace=\"financical-data-00\",\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    sparse_encoder_path=\"../data/sparse_encoder_01.pkl\",\n",
    "    stopwords=stopwords(),\n",
    "    tokenizer=\"kiwi\",\n",
    "    embeddings=UpstageEmbeddings(model=\"solar-embedding-1-large-query\"),\n",
    "    top_k=10,\n",
    "    alpha=0.4,  # alpha=0.75로 설정한 경우, (0.75: Dense Embedding, 0.25: Sparse Embedding)\n",
    ")\n",
    "\n",
    "\n",
    "pinecone_retriever = PineconeKiwiHybridRetriever(**pinecone_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "compressor = CohereRerank(model=\"rerank-multilingual-v3.0\")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=pinecone_retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\"90년대 사건들을 나열해줘\")\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.document_compressors import JinaRerank\n",
    "\n",
    "compressor = JinaRerank(model=\"jina-reranker-v2-base-multilingual\", top_n=5)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=pinecone_retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\"90년대 사건들을 나열해줘\")\n",
    "\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bge-reranker-v2-m3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "\n",
    "compressor = CrossEncoderReranker(model=model, top_n=5)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=pinecone_retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\"90년대 사건들을 나열해줘\")\n",
    "\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ko-reranker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name=\"Dongjin-kr/ko-reranker\")\n",
    "\n",
    "compressor = CrossEncoderReranker(model=model, top_n=5)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=pinecone_retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\"90년대 사건들을 나열해줘\")\n",
    "\n",
    "compressed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranker TestSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from DataProcessing.utils import load_yaml\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "from langchain_community.document_compressors import JinaRerank\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "\n",
    "reranker_list = [\"cohere\", \"jina\", \"bge\", \"ko-reranker\"]\n",
    "\n",
    "for reranker in reranker_list:\n",
    "    path = \"./data/custom_testdataset.xlsx\"\n",
    "    # testset = pd.read_csv(path)\n",
    "    testset = pd.read_excel(path)\n",
    "\n",
    "    questions = testset[\"question\"].to_list()\n",
    "    ground_truth = testset[\"ground_truth\"].to_list()\n",
    "\n",
    "    data = {\"question\": [], \"answer\": [], \"contexts\": [], \"ground_truth\": ground_truth}\n",
    "\n",
    "    prompt_template = load_yaml(\"../prompts/Retriever._prompt.yaml\")[\"prompt\"]\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    # llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "    llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0.5)\n",
    "\n",
    "    if reranker == \"cohere\":\n",
    "        compressor = CohereRerank(model=\"rerank-multilingual-v3.0\")\n",
    "    elif reranker == \"jina\":\n",
    "        compressor = JinaRerank(model=\"jina-reranker-v2-base-multilingual\", top_n=5)\n",
    "    elif reranker == \"bge\":\n",
    "        model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "        compressor = CrossEncoderReranker(model=model, top_n=5)\n",
    "    elif reranker == \"ko-reranker\":\n",
    "        model = HuggingFaceCrossEncoder(model_name=\"Dongjin-kr/ko-reranker\")\n",
    "        compressor = CrossEncoderReranker(model=model, top_n=5)\n",
    "\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=pinecone_retriever\n",
    "    )\n",
    "\n",
    "    rag_chain = (\n",
    "        {\"context\": compression_retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    for query in questions:\n",
    "        data[\"question\"].append(query)\n",
    "        data[\"answer\"].append(rag_chain.invoke(query))\n",
    "        data[\"contexts\"].append(\n",
    "            [doc.page_content for doc in compression_retriever.invoke(query)]\n",
    "        )\n",
    "\n",
    "    path = f\"./data/customtestset_sonnet_bm25_{reranker}.json\"\n",
    "    with open(path, \"w\") as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "from langchain_upstage.embeddings import UpstageEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def run_evaluate(json_path: str, testcount: int = 0):\n",
    "    load_dotenv()\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    filename = os.path.basename(json_path).split(\".\")[0]\n",
    "\n",
    "    dataset = Dataset.from_dict(json_data)\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "    embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")\n",
    "\n",
    "    result = evaluate(\n",
    "        dataset=dataset,\n",
    "        metrics=[\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "        ],\n",
    "        llm=llm,\n",
    "        embeddings=embeddings,\n",
    "    )\n",
    "\n",
    "    df = result.to_pandas()\n",
    "    df.to_csv(f\"./data/results/result_{filename}_{testcount}.csv\")\n",
    "\n",
    "\n",
    "base_path = \"./data\"\n",
    "json_list = [\n",
    "    x for x in os.listdir(base_path) if x.startswith(\"customtestset_sonnet_bm25\")\n",
    "]\n",
    "print(json_list)\n",
    "for path in json_list:\n",
    "    file_path = os.path.join(base_path, path)\n",
    "    run_evaluate(file_path, 0)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = \"./data/results\"\n",
    "result_list = os.listdir(base_path)\n",
    "\n",
    "\n",
    "def print_describe(base_path, filename):\n",
    "    path = os.path.join(base_path, filename)\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df = df[[\"context_precision\", \"context_recall\", \"faithfulness\", \"answer_relevancy\"]]\n",
    "    return df.agg([\"mean\", \"std\"])\n",
    "\n",
    "\n",
    "result_df_mean = pd.DataFrame()\n",
    "result_df_std = pd.DataFrame()\n",
    "\n",
    "for file in result_list:\n",
    "    if file.startswith(\"result_customtestset_sonnet_bm25\"):\n",
    "        result = print_describe(base_path, file)\n",
    "        file_name = file.replace(\"result_customtestset_\", \"\").replace(\"_0.csv\", \"\")\n",
    "\n",
    "        result_mean = result.loc[\"mean\"]\n",
    "        result_mean[\"파일명\"] = file_name\n",
    "        result_df_mean = pd.concat([result_df_mean, result_mean.to_frame().T])\n",
    "\n",
    "        result_std = result.loc[\"std\"]\n",
    "        result_std[\"파일명\"] = file_name\n",
    "        result_df_std = pd.concat([result_df_std, result_std.to_frame().T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>파일명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.966393</td>\n",
       "      <td>0.549444</td>\n",
       "      <td>0.695256</td>\n",
       "      <td>0.036348</td>\n",
       "      <td>sonnet_bm25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.780321</td>\n",
       "      <td>0.055719</td>\n",
       "      <td>sonnet_bm25_bge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.452857</td>\n",
       "      <td>0.667213</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>sonnet_bm25_cohere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.240714</td>\n",
       "      <td>0.628002</td>\n",
       "      <td>0.032591</td>\n",
       "      <td>sonnet_bm25_jina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.98875</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.629102</td>\n",
       "      <td>0.025016</td>\n",
       "      <td>sonnet_bm25_ko-reranker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     context_precision context_recall faithfulness answer_relevancy  \\\n",
       "mean          0.966393       0.549444     0.695256         0.036348   \n",
       "mean               1.0       0.253333     0.780321         0.055719   \n",
       "mean               1.0       0.452857     0.667213         0.049887   \n",
       "mean           0.98875       0.240714     0.628002         0.032591   \n",
       "mean           0.98875           0.52     0.629102         0.025016   \n",
       "\n",
       "                          파일명  \n",
       "mean              sonnet_bm25  \n",
       "mean          sonnet_bm25_bge  \n",
       "mean       sonnet_bm25_cohere  \n",
       "mean         sonnet_bm25_jina  \n",
       "mean  sonnet_bm25_ko-reranker  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>파일명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074134</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>0.38319</td>\n",
       "      <td>0.089534</td>\n",
       "      <td>sonnet_bm25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327806</td>\n",
       "      <td>0.345748</td>\n",
       "      <td>0.121834</td>\n",
       "      <td>sonnet_bm25_bge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429842</td>\n",
       "      <td>0.434855</td>\n",
       "      <td>0.096625</td>\n",
       "      <td>sonnet_bm25_cohere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.38841</td>\n",
       "      <td>0.338389</td>\n",
       "      <td>0.084572</td>\n",
       "      <td>sonnet_bm25_jina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.473286</td>\n",
       "      <td>0.347224</td>\n",
       "      <td>0.06592</td>\n",
       "      <td>sonnet_bm25_ko-reranker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    context_precision context_recall faithfulness answer_relevancy  \\\n",
       "std          0.074134       0.449237      0.38319         0.089534   \n",
       "std               0.0       0.327806     0.345748         0.121834   \n",
       "std               0.0       0.429842     0.434855         0.096625   \n",
       "std          0.035576        0.38841     0.338389         0.084572   \n",
       "std          0.035576       0.473286     0.347224          0.06592   \n",
       "\n",
       "                         파일명  \n",
       "std              sonnet_bm25  \n",
       "std          sonnet_bm25_bge  \n",
       "std       sonnet_bm25_cohere  \n",
       "std         sonnet_bm25_jina  \n",
       "std  sonnet_bm25_ko-reranker  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macroagent-withrag-bsFmSw79-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
