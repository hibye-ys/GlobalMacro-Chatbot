{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    title: str\n",
    "    filepath: str\n",
    "    filetype: str\n",
    "    page_numbers: list[int]\n",
    "    page_elements: dict[int, dict[str, list[dict]]]\n",
    "    page_metadata: dict[int, dict]\n",
    "    page_summary: dict[int, str]\n",
    "    images: list[str]\n",
    "    images_summary: list[str]\n",
    "    texts: list[str]\n",
    "    texts_summary: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "import re\n",
    "import os\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_upstage.embeddings import UpstageEmbeddings\n",
    "from langchain_upstage.chat_models import ChatUpstage\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def split_document(state: GraphState):\n",
    "    file_path = state[\"filepath\"]\n",
    "    data = open(file_path, \"r\", encoding=\"utf-8\")\n",
    "    doc = data.read()\n",
    "\n",
    "    title = os.path.basename(file_path)\n",
    "    filetype = title.split(\".\")[-1]\n",
    "\n",
    "    image_pattern = re.compile(r\"!\\[.*?\\]\\(.*?\\)\")\n",
    "\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "        (\"####\", \"Header 4\"),\n",
    "    ]\n",
    "\n",
    "    if filetype == \"md\":  # -> List[Document]\n",
    "        splitter = MarkdownHeaderTextSplitter(\n",
    "            headers_to_split_on=headers_to_split_on, strip_headers=False\n",
    "        )\n",
    "    elif filetype == \"txt\":  # -> List[str]\n",
    "        embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")\n",
    "        splitter = SemanticChunker(embeddings=embeddings)\n",
    "\n",
    "    split_docs = splitter.split_text(doc)\n",
    "\n",
    "    llm = ChatUpstage()\n",
    "    embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")\n",
    "    splited_docs = []\n",
    "    for document in split_docs:\n",
    "        if llm.get_num_tokens(document.page_content) > 3000:\n",
    "            splitter2 = SemanticChunker(embeddings=embeddings)\n",
    "            page_contents = splitter2.split_text(document.page_content)\n",
    "            for content in page_contents:\n",
    "                splited_docs.append(\n",
    "                    Document(page_content=content, metadata=document.metadata)\n",
    "                )\n",
    "        else:\n",
    "            splited_docs.append(document)\n",
    "    num_pages = [x for x in range(len(splited_docs))]\n",
    "    image_pattern = re.compile(r\"!\\[.*?\\]\\(.*?\\)\")\n",
    "\n",
    "    page_elements = dict()\n",
    "    page_metadata = dict()\n",
    "    id = 0\n",
    "    for i, split_doc in enumerate(splited_docs):\n",
    "        page_elements[i] = []\n",
    "        page_metadata[i] = split_doc.metadata\n",
    "        images = image_pattern.findall(\n",
    "            split_doc.page_content if filetype == \"md\" else split_doc\n",
    "        )\n",
    "        split_texts = image_pattern.split(\n",
    "            split_doc.page_content if filetype == \"md\" else split_doc\n",
    "        )\n",
    "\n",
    "        for j, text in enumerate(split_texts):\n",
    "            page_elements[i].append(\n",
    "                {\"id\": id, \"page\": i, \"type\": \"text\", \"content\": text}\n",
    "            )\n",
    "            id += 1\n",
    "            if j < len(images):\n",
    "                page_elements[i].append(\n",
    "                    {\"id\": id, \"page\": i, \"type\": \"image\", \"content\": images[j]}\n",
    "                )\n",
    "                id += 1\n",
    "\n",
    "    return GraphState(\n",
    "        page_numbers=num_pages,\n",
    "        page_elements=page_elements,\n",
    "        page_metadata=page_metadata,\n",
    "        title=title,\n",
    "        filetype=filetype,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_elements_per_page(state: GraphState):\n",
    "    # GraphState 객체에서 페이지 요소들을 가져옵니다.\n",
    "    page_elements = state[\"page_elements\"]\n",
    "\n",
    "    # 파싱된 페이지 요소들을 저장할 새로운 딕셔너리를 생성합니다.\n",
    "    parsed_page_elements = dict()\n",
    "\n",
    "    # 각 페이지와 해당 페이지의 요소들을 순회합니다.\n",
    "    for key, page_element in page_elements.items():\n",
    "        # 이미지, 테이블, 텍스트 요소들을 저장할 리스트를 초기화합니다.\n",
    "        image_elements = []\n",
    "        table_elements = []\n",
    "        text_elements = []\n",
    "\n",
    "        # 페이지의 각 요소를 순회하며 카테고리별로 분류합니다.\n",
    "        for element in page_element:\n",
    "            print(element)\n",
    "            if element[\"type\"] == \"image\":\n",
    "                # 이미지 요소인 경우 image_elements 리스트에 추가합니다.\n",
    "                image_url = element[\"content\"].split(\"](\")[1].split(\")\")[0]\n",
    "                element[\"content\"] = image_url\n",
    "                image_elements.append(element)\n",
    "            elif element[\"type\"] == \"table\":\n",
    "                # 테이블 요소인 경우 table_elements 리스트에 추가합니다.\n",
    "                table_elements.append(element)\n",
    "            else:\n",
    "                # 그 외의 요소는 모두 텍스트 요소로 간주하여 text_elements 리스트에 추가합니다.\n",
    "                text_elements.append(element)\n",
    "\n",
    "        # 분류된 요소들을 페이지 키와 함께 새로운 딕셔너리에 저장합니다.\n",
    "        parsed_page_elements[key] = {\n",
    "            \"image_elements\": image_elements,\n",
    "            \"table_elements\": table_elements,\n",
    "            \"text_elements\": text_elements,\n",
    "            \"elements\": page_element,  # 원본 페이지 요소도 함께 저장합니다.\n",
    "        }\n",
    "\n",
    "    # 파싱된 페이지 요소들을 포함한 새로운 GraphState 객체를 반환합니다.\n",
    "    return GraphState(page_elements=parsed_page_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_text(state: GraphState):\n",
    "    # 상태 객체에서 페이지 번호 목록을 가져옵니다.\n",
    "    page_numbers = state[\"page_numbers\"]\n",
    "\n",
    "    # 추출된 텍스트를 저장할 딕셔너리를 초기화합니다.\n",
    "    extracted_texts = dict()\n",
    "\n",
    "    # 각 페이지 번호에 대해 반복합니다.\n",
    "    for page_num in page_numbers:\n",
    "        # 현재 페이지의 텍스트를 저장할 빈 문자열을 초기화합니다.\n",
    "        extracted_texts[page_num] = \"\"\n",
    "\n",
    "        # 현재 페이지의 모든 텍스트 요소에 대해 반복합니다.\n",
    "        for element in state[\"page_elements\"][page_num][\"text_elements\"]:\n",
    "            # 각 텍스트 요소의 내용을 현재 페이지의 텍스트에 추가합니다.\n",
    "            extracted_texts[page_num] += element[\"content\"]\n",
    "\n",
    "    # 추출된 텍스트를 포함한 새로운 GraphState 객체를 반환합니다.\n",
    "    return GraphState(texts=extracted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from summarizer import Summarizer\n",
    "from utils import load_yaml\n",
    "\n",
    "\n",
    "def create_text_summary(state: GraphState):\n",
    "    # state에서 텍스트 데이터를 가져옵니다.\n",
    "    texts = state[\"texts\"]\n",
    "    config = load_yaml(\"../config/GraphState.yaml\")\n",
    "    # 요약된 텍스트를 저장할 딕셔너리를 초기화합니다.\n",
    "    text_summary = dict()\n",
    "    # texts.items()를 페이지 번호(키)를 기준으로 오름차순 정렬합니다.\n",
    "    sorted_texts = sorted(texts.items(), key=lambda x: x[0])\n",
    "\n",
    "    # 각 페이지의 텍스트를 Document 객체로 변환하여 입력 리스트를 생성합니다.\n",
    "    inputs = [Document(page_content=text) for _, text in sorted_texts]\n",
    "\n",
    "    summarizer = Summarizer(config=config, summary_type=\"only_cod\", use_cod=True)\n",
    "\n",
    "    summaries = summarizer.chain_of_density(inputs)\n",
    "\n",
    "    # 생성된 요약을 페이지 번호와 함께 딕셔너리에 저장합니다.\n",
    "    for page_num, summary in enumerate(summaries):\n",
    "        text_summary[page_num] = summary\n",
    "\n",
    "    # 요약된 텍스트를 포함한 새로운 GraphState 객체를 반환합니다.\n",
    "    return GraphState(text_summary=text_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_summary_data_batches(state: GraphState):\n",
    "    # 이미지 요약을 위한 데이터 배치를 생성하는 함수\n",
    "    data_batches = []\n",
    "    images = {}\n",
    "\n",
    "    # 페이지 번호를 오름차순으로 정렬\n",
    "    page_numbers = sorted(list(state[\"page_elements\"].keys()))\n",
    "\n",
    "    for page_num in page_numbers:\n",
    "        # 각 페이지의 요약된 텍스트를 가져옴\n",
    "        text = state[\"text_summary\"][page_num]\n",
    "        # 해당 페이지의 모든 이미지 요소에 대해 반복\n",
    "        for image_element in state[\"page_elements\"][page_num][\"image_elements\"]:\n",
    "            # 이미지 ID를 정수로 변환\n",
    "            image_id = int(image_element[\"id\"])\n",
    "\n",
    "            # 데이터 배치에 이미지 정보, 관련 텍스트, 페이지 번호, ID를 추가\n",
    "            data_batches.append(\n",
    "                {\n",
    "                    \"image\": image_element[\"content\"],  # 이미지 파일 경로\n",
    "                    \"text\": text,  # 관련 텍스트 요약\n",
    "                    \"page\": page_num,  # 페이지 번호\n",
    "                    \"id\": image_id,  # 이미지 ID\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # images 딕셔너리에 이미지 요소 추가\n",
    "            images[image_id] = image_element[\"content\"]\n",
    "\n",
    "    # 생성된 데이터 배치와 이미지를 GraphState 객체에 담아 반환\n",
    "    return GraphState(image_summary_data_batches=data_batches, images=images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.models import MultiModal\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def extract_image_summary(data_batches):\n",
    "    # 객체 생성\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "        model_name=\"gpt-4o-mini\",  # 모델명\n",
    "    )\n",
    "\n",
    "    system_prompt = \"\"\"You are an expert in extracting useful information from IMAGE.\n",
    "    With a given image, your task is to extract key entities, summarize them, and write useful information that can be used later for retrieval in Korean.\"\"\"\n",
    "\n",
    "    image_paths = []\n",
    "    system_prompts = []\n",
    "    user_prompts = []\n",
    "\n",
    "    for data_batch in data_batches:\n",
    "        context = data_batch[\"text\"]\n",
    "        image_path = data_batch[\"image\"]\n",
    "        user_prompt_template = f\"\"\"Here is the context related to the image: {context}\n",
    "        \n",
    "###\n",
    "\n",
    "Output Format:\n",
    "\n",
    "<image>\n",
    "<title>\n",
    "<summary>\n",
    "<entities> \n",
    "</image>\n",
    "\n",
    "\"\"\"\n",
    "        image_paths.append(image_path)\n",
    "        system_prompts.append(system_prompt)\n",
    "        user_prompts.append(user_prompt_template)\n",
    "\n",
    "    multimodal_llm = MultiModal(llm)\n",
    "\n",
    "    \"\"\"answer = multimodal_llm.batch(\n",
    "        image_paths, system_prompts, user_prompts, display_image=False\n",
    "    )\"\"\"\n",
    "\n",
    "    answers = []\n",
    "\n",
    "    # 각 배치를 개별적으로 처리\n",
    "    for i in range(len(image_paths)):\n",
    "        try:\n",
    "            # 단일 이미지에 대한 질의 실행\n",
    "            result = multimodal_llm.batch(\n",
    "                [image_paths[i]],\n",
    "                [system_prompts[i]],\n",
    "                [user_prompts[i]],\n",
    "                display_image=False,\n",
    "            )\n",
    "            answers.extend(result)\n",
    "        except Exception as e:\n",
    "            print(f\"배치 {i} 처리 중 오류 발생: {str(e)}\")\n",
    "            # 오류 발생 시 빈 문자열 추가\n",
    "            answers.append(\"\")\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "def create_image_summary(state: GraphState):\n",
    "    image_summary_output = dict()\n",
    "\n",
    "    try:\n",
    "        image_summaries = extract_image_summary.invoke(\n",
    "            state[\"image_summary_data_batches\"],\n",
    "        )\n",
    "\n",
    "        for data_batch, image_summary in zip(\n",
    "            state[\"image_summary_data_batches\"], image_summaries\n",
    "        ):\n",
    "            image_summary_output[data_batch[\"id\"]] = image_summary\n",
    "    except Exception as e:\n",
    "        logging.error(f\"이미지 요약 생성 중 오류 발생: {str(e)}\")\n",
    "\n",
    "    return GraphState(image_summary=image_summary_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_community.document_transformers.openai_functions import (\n",
    "    create_metadata_tagger,\n",
    ")\n",
    "from langchain.docstore.document import Document\n",
    "from datetime import datetime\n",
    "from utils import load_yaml\n",
    "from metadata_properties import Property1\n",
    "\n",
    "prompt = load_yaml(\"../prompts/metadatatagger.yaml\")[\"prompt\"]\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0.1)\n",
    "\n",
    "\n",
    "def create_metadata(state: GraphState):\n",
    "    page_num = state[\"page_numbers\"]\n",
    "\n",
    "    split_docs = []\n",
    "    for num in page_num:\n",
    "        texts = state[\"texts\"][num]\n",
    "        metadata = state[\"page_metadata\"][num]\n",
    "\n",
    "        data = \"\\n\".join(texts)\n",
    "\n",
    "        if \"images_summary\" in state and num in state[\"images_summary\"]:\n",
    "            image_summary = state[\"images_summary\"][num]\n",
    "            data += f\"\\n{image_summary}\"\n",
    "\n",
    "        split_docs.append(Document(page_content=data, metadata=metadata))\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    merged_documents = []\n",
    "    for doc in split_docs:\n",
    "\n",
    "        merged_content = (\n",
    "            f\"metadata:{doc.metadata}\\n\\n ---- \\n page_content:{doc.page_content}\"\n",
    "        )\n",
    "\n",
    "        merged_documents.append(\n",
    "            Document(page_content=merged_content, metadata=doc.metadata)\n",
    "        )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    document_transformer = create_metadata_tagger(Property1, llm)\n",
    "    enhanced_documents = document_transformer.transform_documents(\n",
    "        merged_documents, prompt=prompt\n",
    "    )\n",
    "\n",
    "    metadata = dict()\n",
    "    for i in range(len(split_docs)):\n",
    "        metadata[i] = []\n",
    "        metadata[i] = enhanced_documents[i].metadata\n",
    "\n",
    "    return GraphState(page_metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "\n",
    "def save_state_to_json(state, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(state, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "def get_files_by_type(directory: str, file_type: str) -> List[str]:\n",
    "    return [\n",
    "        os.path.join(directory, f)\n",
    "        for f in os.listdir(directory)\n",
    "        if f.endswith(f\".{file_type}\")\n",
    "    ]\n",
    "\n",
    "\n",
    "def process_file(file_path: str, output_path: str):\n",
    "    try:\n",
    "        state = GraphState(filepath=file_path)\n",
    "\n",
    "        logging.info(\"split_document 시작\")\n",
    "        state_out = split_document(state)\n",
    "        state.update(state_out)\n",
    "\n",
    "        logging.info(\"extract_elements_per_page 시작\")\n",
    "        state_out = extract_elements_per_page(state)\n",
    "        state.update(state_out)\n",
    "\n",
    "        logging.info(\"extract_page_text 시작\")\n",
    "        state_out = extract_page_text(state)\n",
    "        state.update(state_out)\n",
    "\n",
    "        logging.info(\"create_text_summary 시작\")\n",
    "        state_out = create_text_summary(state)\n",
    "        state.update(state_out)\n",
    "\n",
    "        has_image_elements = any(\n",
    "            \"image_elements\" in page and page[\"image_elements\"]\n",
    "            for page in state[\"page_elements\"].values()\n",
    "        )\n",
    "\n",
    "        if has_image_elements:\n",
    "            logging.info(\"create_image_summary_data_batches 시작\")\n",
    "            state_out = create_image_summary_data_batches(state)\n",
    "            state.update(state_out)\n",
    "\n",
    "            logging.info(\"create_image_summary 시작\")\n",
    "            state_out = create_image_summary(state)\n",
    "            state.update(state_out)\n",
    "        else:\n",
    "            logging.info(\"이미지 요소가 없어 이미지 요약 과정을 건너뜁니다.\")\n",
    "\n",
    "        logging.info(\"create_metadata 시작\")\n",
    "        state_out = create_metadata(state)\n",
    "        state.update(state_out)\n",
    "\n",
    "        filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        json_path = f\"{output_path}/{filename}.json\"\n",
    "        save_state_to_json(state, json_path)\n",
    "\n",
    "        logging.info(f\"파일 처리 완료: {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"파일 처리 중 오류 발생: {file_path}. 오류: {str(e)}\")\n",
    "        logging.exception(\"상세 오류 정보:\")\n",
    "        raise Exception(f\"파일 처리 중 오류로 인해 프로그램을 중단합니다: {file_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = load_yaml(\"../config/GraphState.yaml\")\n",
    "    base_path = config[\"settings\"][\"base_path\"]\n",
    "    edit_path = config[\"settings\"][\"edit_path\"]\n",
    "    category_id = config[\"settings\"][\"category_id\"]\n",
    "    filetype = config[\"settings\"][\"filetype\"]\n",
    "\n",
    "    output_path = os.path.join(edit_path, category_id, \"json\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    input_directory = os.path.join(base_path, category_id, filetype)\n",
    "\n",
    "    files = get_files_by_type(input_directory, filetype)\n",
    "\n",
    "    for file in files:\n",
    "        filename = os.path.splitext(os.path.basename(file))[0]\n",
    "        json_path = f\"{output_path}/{filename}.json\"\n",
    "\n",
    "        if os.path.exists(json_path):\n",
    "            logging.info(f\"이미 처리된 파일입니다. 건너뜁니다: {file}\")\n",
    "            continue\n",
    "\n",
    "        process_file(file, output_path)\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macroagent-withrag-bsFmSw79-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
