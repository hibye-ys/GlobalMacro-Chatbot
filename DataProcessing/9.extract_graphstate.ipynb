{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multivector retriever\n",
    "\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def extract_documents_for_docstore(json_data: Dict) -> List[Document]:\n",
    "    documents = []\n",
    "    for page_num, page_data in json_data[\"page_elements\"].items():\n",
    "        elements = sorted(page_data[\"elements\"], key=lambda x: x[\"id\"])\n",
    "        page_content = \"\\n\".join([element[\"content\"] for element in elements])\n",
    "        page_metadata = json_data[\"page_metadata\"][str(page_num)]\n",
    "        metadata = {\n",
    "            \"id\": page_num,\n",
    "            \"page\": int(page_num),\n",
    "            \"images\": (\n",
    "                json_data[\"images\"].get(page_num, \"\") if \"images\" in json_data else []\n",
    "            ),\n",
    "            \"doc_id\": f\"{json_data['title']}_{page_num}\",\n",
    "            **page_metadata,\n",
    "        }\n",
    "        documents.append(Document(page_content=page_content, metadata=metadata))\n",
    "    return documents\n",
    "\n",
    "\n",
    "def extract_documents_for_vectorstore(json_data: Dict) -> List[Document]:\n",
    "    documents = []\n",
    "    for page_num, summary in json_data[\"text_summary\"].items():\n",
    "        page_content = summary\n",
    "        if page_num in json_data[\"image_summary\"]:\n",
    "            page_content += \"\\n\" + json_data[\"image_summary\"][page_num]\n",
    "        page_metadata = json_data[\"page_metadata\"][str(page_num)]\n",
    "        metadata = {\n",
    "            \"page\": int(page_num),\n",
    "            \"images\": (\n",
    "                json_data[\"images\"].get(page_num, \"\") if \"images\" in json_data else []\n",
    "            ),\n",
    "            \"doc_id\": f\"{json_data['title']}_{page_num}\",\n",
    "            **page_metadata,\n",
    "        }\n",
    "        documents.append(Document(page_content=page_content, metadata=metadata))\n",
    "    return documents\n",
    "\n",
    "\n",
    "json_path = \"\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "docstore_documents = extract_documents_for_docstore(json_data)\n",
    "\n",
    "vectorstore_documents = extract_documents_for_vectorstore(json_data)\n",
    "\n",
    "print(\"Docstore Documents:\")\n",
    "for doc in docstore_documents:\n",
    "    print(f\"Page content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"---\")\n",
    "\n",
    "print(\"\\nVectorstore Documents:\")\n",
    "for doc in vectorstore_documents:\n",
    "    print(f\"Page content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import json\n",
    "\n",
    "\n",
    "def extract_documents_for_single_store(json_path: str) -> list[Document]:\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for page_number, page_data in data[\"page_elements\"].items():\n",
    "        page_content = \"\"\n",
    "        images = []\n",
    "\n",
    "        for element in page_data[\"elements\"]:\n",
    "            if element[\"type\"] == \"text\":\n",
    "                page_content += f\"<text>{element['content']}</text>\\n\"\n",
    "            elif element[\"type\"] == \"image\":\n",
    "                image_id = element[\"id\"]\n",
    "                image_summary = data[\"image_summary\"].get(\n",
    "                    str(image_id), \"이미지 설명 없음\"\n",
    "                )\n",
    "                page_content += f\"{image_summary}\\n\"\n",
    "                images.append(element[\"content\"])\n",
    "\n",
    "        page_metadata = data[\"page_metadata\"].get(page_number, {})\n",
    "        page_metadata[\"page_number\"] = int(page_number)\n",
    "\n",
    "        doc = Document(\n",
    "            page_content=page_content,\n",
    "            metadata={\n",
    "                **page_metadata,\n",
    "                \"images\": images,\n",
    "                \"doc_id\": f\"{data['title']}_{page_number}\",\n",
    "            },\n",
    "        )\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "# 함수 사용 예시\n",
    "json_path = \"\"\n",
    "documents = extract_documents_for_single_store(json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macroagent-withrag-bsFmSw79-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
