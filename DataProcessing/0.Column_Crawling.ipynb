{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "from urllib.parse import urljoin\n",
    "import html2text\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import yaml\n",
    "\n",
    "\n",
    "class ColumnCrawler:\n",
    "    def __init__(self, config, column=None):\n",
    "        self.category_id = config[\"settings\"][\"category_id\"]\n",
    "        self.url_category = config[\"settings\"][\"url_category\"]\n",
    "        self.driver = None\n",
    "        self.each_column = column\n",
    "        self.filetype = config[\"settings\"][\"filetype\"]\n",
    "        self.base_url = config[\"settings\"][\"base_url\"]\n",
    "        self.base_path = config[\"settings\"][\"base_path\"]\n",
    "        self.folder_path = os.path.join(self.base_path, self.category_id, self.filetype)\n",
    "\n",
    "    def start_chrome_debugging(self):\n",
    "        chrome_path = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n",
    "        debugging_port = \"9222\"\n",
    "        subprocess.Popen([chrome_path, f\"--remote-debugging-port={debugging_port}\"])\n",
    "        time.sleep(2)\n",
    "\n",
    "    def setup_selenium_driver(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\")\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        self.driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    def get_column_links(self):\n",
    "        self.driver.get(f\"{self.base_url}/{self.url_category}\")\n",
    "        WebDriverWait(self.driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "        links = soup.find_all(\n",
    "            \"a\",\n",
    "            class_=\"group/link mr-auto flex w-full min-w-0 flex-col gap-1 visited:text-fuchsia-900 xl:flex-row xl:gap-0\",\n",
    "        )\n",
    "        return [f\"{self.base_url}{link['href']}\" for link in links if link.get(\"href\")]\n",
    "\n",
    "    def parse_page_text(self, url):\n",
    "        self.driver.get(url)\n",
    "        WebDriverWait(self.driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        title = soup.find(\n",
    "            \"h3\", \"flex w-full items-center gap-1.5 break-words text-base font-medium\"\n",
    "        )\n",
    "        article = soup.find(\n",
    "            \"div\",\n",
    "            \"prose prose-hr:my-6 max-w-none overflow-x-auto whitespace-break-spaces prose-sm\",\n",
    "        )\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        if not article:\n",
    "            return \"본문을 찾을 수 없습니다.\", \"\"\n",
    "\n",
    "        for img in article.find_all(\"img\"):\n",
    "            if img.get(\"src\"):\n",
    "                img[\"src\"] = urljoin(url, img[\"src\"])\n",
    "\n",
    "        def custom_image_formatter(tag):\n",
    "            src = tag.get(\"src\", \"\")\n",
    "            alt = tag.get(\"alt\", \"\")\n",
    "            return f\"![{alt}]({src})\\n\\n\"\n",
    "\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.ignore_images = False\n",
    "        h.protect_links = True\n",
    "        h.images_to_alt = False\n",
    "        h.images_as_html = False\n",
    "        h.body_width = 0\n",
    "        h.custom_tag_formatter = custom_image_formatter\n",
    "        markdown_content = h.handle(str(article))\n",
    "\n",
    "        return title.get_text(strip=True), markdown_content\n",
    "\n",
    "    def save_markdown_file(self, title, markdown_content):\n",
    "        md_filename = f\"{title}.md\"\n",
    "        md_path = os.path.join(self.folder_path, md_filename)\n",
    "\n",
    "        if not os.path.exists(self.folder_path):\n",
    "            os.makedirs(self.folder_path)\n",
    "\n",
    "        with open(md_path, \"w\", encoding=\"utf-8\") as md_file:\n",
    "            md_file.write(f\"# {title}\\n\\n\")\n",
    "            md_file.write(markdown_content)\n",
    "\n",
    "        print()\n",
    "\n",
    "        return md_path\n",
    "\n",
    "    def crawl_and_save(self):\n",
    "        self.start_chrome_debugging()\n",
    "        self.setup_selenium_driver()\n",
    "\n",
    "        if self.each_column is not None:\n",
    "            title, markdown_content = self.parse_page_text(self.each_column)\n",
    "            self.save_markdown_file(title, markdown_content)\n",
    "            print(f\"{title}이 저장되었습니다\")\n",
    "            time.sleep(10)\n",
    "\n",
    "        else:\n",
    "            links = self.get_column_links()\n",
    "            for link in links:\n",
    "                title, markdown_content = self.parse_page_text(link)\n",
    "                self.save_markdown_file(title, markdown_content)\n",
    "                print(f\"{title}이 저장되었습니다\")\n",
    "                time.sleep(10)\n",
    "\n",
    "        self.driver.quit()\n",
    "\n",
    "\n",
    "def load_yaml(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "config = load_yaml(\"../config/crawler.yaml\")\n",
    "\n",
    "# 개별 컬럼 md 저장\n",
    "column = config[\"settings\"][\"column\"]\n",
    "\n",
    "crawler = ColumnCrawler(config, column)\n",
    "crawler.crawl_and_save()\n",
    "\n",
    "\n",
    "# 페이지내 여러 칼럼 md 저장\n",
    "# crawler = ColumnCrawler(config)\n",
    "# crawler.crawl_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-CK8n2Lx5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
